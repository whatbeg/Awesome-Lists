## ICML 2017

* Toward Efficient and Accurate Covariance Matrix Estimation on Compressed Data
XIXIAN CHEN (The Chinese University of Hong Kong) · Irwin King (CUHK) · Michael Lyu (The Chinese University of Hong Kong)

* Combined Group and Exclusive Sparsity for Deep Neural Networks
jaehong yoon (UNIST) · Sung Hwang ()

* SplitNet: Learning to Semantically Split Deep Networks for Parameter Reduction and Model Parallelization
Juyong Kim (Seoul National University) · Yookoon Park (Seoul National University) · Gunhee Kim (Seoul National University) · Sung Hwang ()

* Conditional Accelerated Lazy Stochastic Gradient Descent
Guanghui Lan () · Sebastian Pokutta (Georgia Tech) · Yi Zhou () · Daniel Zink ()

* Cognitive Psychology for Deep Neural Networks: A Shape Bias Case Study
Samual Ritter (DeepMind) · David GT Barrett (DeepMind) · Adam Santoro (DeepMind) · Matthew Botvinick (DeepMind)

* Accelerated Stochastic Gradient Expectation-Maximization Algorithm
Rongda Zhu (UIUC) · Lingxiao Wang (University of Virginia) · Chengxiang Zhai (University of Illinois at Urbana-Champaign) · Quanquan Gu (University of Virginia)

* **Asynchronous Stochastic Gradient Descent with Delay Compensation**
Shuxin Zheng (University of Science and Technology of China) · Qi Meng (Peking University) · Taifeng Wang () · Wei Chen (Microsoft Research) · Tie-Yan Liu (Microsoft)

* meProp: Minimal Effort Back Propagation for Accelerated Deep Learning
Xu SUN (Peking University) · Xuanchen Ren () · Shuming Ma () · Houfeng Wang ()

* A Distributional Perspective on Reinforcement Learning
Marc Bellemare (DeepMind) · Will Dabney (DeepMind) · Remi Munos (Google DeepMind)

* **Efficient Distributed Learning with Sparsity**
Jialei Wang (University of Chicago) · Mladen Kolar (University of Chicago) · Nati Srebro (Toyota Technological Institute at Chicago) · Tong Zhang ()

* The Shattered Gradients Problem: If resnets are the answer, then what is the question?
David Balduzzi (Victoria University Wellington) · Marcus Frean (Victoria University Wellington) · Wan-Duo Ma (Victoria University) · Brian McWilliams (Disney Research) · Lennox Leary (VUW) · J.P. Lewis (Frostbite Labs and Victoria University)

* **Sharp Minima Can Generalize For Deep Nets**
Laurent Dinh (U. Montreal) · Razvan Pascanu (DeepMind) · Samy Bengio (Google Brain) · Yoshua Bengio (U. Montreal)

* Adaptive Consensus ADMM for Distributed Optimization
Zheng Xu (University of Maryland) · Gavin Taylor (US Naval Academy) · Hao Li (University of Maryland at College Park) · Mario Figueiredo (Instituto Superior Tecnico) · Xiaoming Yuan () · Tom Goldstein ()

* **How to Escape Saddle Points Efficiently**
Chi Jin (UC Berkeley) · Rong Ge (Duke University) · Praneeth Netrapalli (Microsoft Research) · Sham M. Kakade (University of Washington) · Michael Jordan ()

* Schema Networks
Ken Kansky (Vicarious Systems FPC, Inc.) · David Mely (Vicarious Systems) · Mohamed Eldawy (Vicarious Systems) · Thomas Silver (Vicarious) · Miguel Lazaro-Gredilla (Vicarious) · Xinghua Lou (Vicarious Systems) · Nimrod Dorfman (Vicarious Systems) · Dileep George (Vicarious) · Scott Phoenix (Vicarious Systems)

* **Failures of Gradient-Based Deep Learning**
Shaked Shammah (Hebrew University Jerusalem Israel) · Shai Shalev-Shwartz () · Ohad Shamir (Weizmann Institute of Science)

* **The loss surface of deep and wide neural networks**
Quynh Nguyen (Saarland University) · Matthias Hein (Saarland University)

* Learned Optimizers that Scale and Generalize
Olga Wichrowska (Google Brain) · Niru Maheswaranathan (Stanford) · Matthew Hoffman (DeepMind) · Sergio Gomez (Google) · Misha Denil (University of Oxford) · Nando de Freitas (DeepMind) · Jascha Sohl-Dickstein (Google Brain)

* Practical Gauss-Newton Optimisation for Deep Learning
Aleksandar Botev (University College London) · (None) · David Barber (University College London)

* On the Expressive Power of Deep Neural Networks
Maithra Raghu (Cornell University) · Ben Poole (Stanford University) · Surya Ganguli (Stanford) · Jon Kleinberg (Cornell University) · Jascha Sohl-Dickstein (Google Brain)

* **Neural Optimizer Search using Reinforcement Learning**
Barret Zoph (Google) · Quoc Le (Google Brain) · Irwan Bello (Google) · Vijay Vasudevan (Google)

* **Gradient Coding: Avoiding Stragglers in Distributed Learning**
Rashish Tandon (University of Texas at Austin) · Qi Lei (University of Texas at Austin) · Alexandros Dimakis (UT Austin) · NIKOS KARAMPATZIAKIS (Microsoft)

* Stochastic Adaptive Quasi-Newton Methods for Minimizing Expected Values
Wenbo Gao (Columbia University) · Donald Goldfarb (Columbia University) · Chaoxu Zhou (Columbia University)

* Learning Gradient Descent: Better Generalization and Longer Horizons
Kaifeng Lv (Tsinghua University) · Shunhua Jiang (Tsinghua University) · Jian Li (IIIS)

